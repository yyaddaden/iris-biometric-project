\documentclass[12pt,twoside,letterpaper]{article}
%NOTE: This report format is 

\newcommand{\reporttitle}{Développement d'un système biométrique pour l'identification basé sur l'iris des yeux}
\newcommand{\reportauthorOne}{François Beaulieu}
% \newcommand{\cidOne}{your id number}
\newcommand{\reportauthorTwo}{Yacine Yaddaden, Ph. D.}
% \newcommand{\cidTwo}{your id number}
\newcommand{\reporttype}{Coursework}
\bibliographystyle{plain}

% include files that load packages and define macros
\input{includes} % various packages needed for maths etc.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
% front page
\input{titlepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%% table of content
%If a table of content is needed, simply uncomment the following lines
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Main document
\section{Introduction}
La sécurité informatique est un sujet qui est très d'actualité. Avec les nombreuses fuites de données des entreprises et les nombreux autres problèmes de sécurité, il est important de mettre en place des mesures de sécurité robustes. Une solution à ces problèmes est d'implémenter un système biométrique. Ces systèmes permettent d'authentifier une personne en utilisant des valeurs biométriques comme l'empreinte digitale, la voix, le visage ou l'iris. Les systèmes biométriques sont très sensibles et précis. Dans ce rapport, j'expliquerai comment j'ai développé un système biométrique basé sur l’iris de l’œil.
\cite{ref_06}

\section{Étude bibliographique}

\cite{ref_07}

\cite{ref_08}

\cite{ref_09}

\cite{ref_10}

\section{Système biométrique basé sur l’iris de l’œil}

Un système biométrique basé sur l'iris de l'oeil comporte plusieurs différentes étapes. Ce processus débute avec une base de données d'iris, ensuite, on procède au pré-traitement, à l'extraction des caractéristiques, à la réduction de dimensionnalité et on termine avec le processus de classification. 

\begin{center}
    \includegraphics[width = 14cm]{schema}
\end{center}

Le processus de création d'un système biométrique basé sur l'iris de l'oeil sera détaillé dans ce qui suit.

\subsection{Base de données d’iris}
Le choix de la base de données d’iris est très important. La qualité des images peut influencer l’analyse des images. Il existe plusieurs bases de données disponibles sur internet.
\\~\\
Les éléments pouvant influencer la qualité des images sont les suivants :
\begin{itemize}
    \item Les sources de lumière
    \item Lentilles
    \item Capteur
    \item Unité de contrôle
\end{itemize}
\cite{ref_01}\cite{ref_06}
\ \\~\\
La base de données utilisée pour ce projet est « MMU iris dataset ». La base de données de « Multimedia University » (MMU1) est une base de données publique composée d'images d'oeil pour l'entraînement de modèles de système biométrique basé sur l'iris de l'oeil. Cet ensemble de données se compose de 5 images de l'iris gauche et droit de 46 personnes, pour un total de 460 images avec quelques fichiers vides.\cite{ref_05}

\subsection{Pré-traitement}
Ce processus consiste à enlever certains artefacts contenus dans les images d’origine, afin d’augmenter la précision de la reconnaissance de l’iris. Parmi les traitements pour retirer ces artefacts, on retrouve la suppression du bruit, la suppression du flou, la suppression des reflets, l’étirement du contraste, la suppression de l’occlusion des cils et la correction de l'angle du regard. Dans le pré-traitement, on doit aussi convertir les images couleurs en gris.\cite{ref_01}\cite{ref_06}


\subsubsection{Segmentation}
La segmentation de l’iris consiste à la détection de toutes les frontières de l’iris et de la pupille. C’est l’extraction de la région d’intérêt. Les techniques « Edge detection » et « Hough Transform » sont très populaires pour la segmentation de l’iris. 
\\~\\
Pour ce projet, j'ai utilisé la technique « Hough Transform » de « scikit-image ». « Hough Transform » dans sa forme la plus simple est une méthode pour détecter des lignes droites, mais elle peut également être utilisée pour détecter des cercles ou des ellipses. Pour détecter un cercle, on fournit un intervalle de rayons plausibles. Pour chaque rayon, des cercles sont extraits et on garde seulement les meilleurs candidats.\cite{ref_04}

\subsubsection{Normalisation}
La normalisation consiste à transformer l’iris circulaire en rectangle pour faciliter l’extraction des caractéristiques. « Daugman’s Rubber Sheet Model » est une méthode de normalisation utilisée pour la reconnaissance de l’iris.\cite{ref_01}\cite{ref_06}
\\~\\
Pour ce projet, j'ai utilisé la méthode « Warp Polar » de « scikit-image » pour transformer l'iris détecté à l'étape précédente en rectangle. Ensuite, j'ai retiré la partie noire (la pupille) de l'image rectangulaire. Pour ce faire, j'ai retiré toutes les lignes de l'image qui contenait 50\% ou plus de pixel avec des valeurs inférieures à (45, 45, 45).

\subsection{Extraction des caractéristiques}
L’extraction des caractéristiques consiste à représenter les caractéristiques de texture, afin de différencier les iris durant le processus de classification.\cite{ref_01}\cite{ref_06}

\subsubsection{GLCM}
Pour l’extraction des caractéristiques de l’iris, on peut utiliser la méthode GLCM (Gray-Level Co-occurrence Matrix). GLCM est une méthode statistique de second ordre pour l'analyse de texture. Les caractéristiques qui résultent des statistiques au premier ordre renseignent sur la répartition des niveaux de gris de l'image. Cependant, ils n'incluent aucune information sur les positions relatives des différents gris au sein de l'image. Les statistiques de second ordre sont utilisées pour fournir ces informations, où les pixels sont pris en compte par paires. Les statistiques du deuxième ordre et des ordres supérieurs prédisent deux valeurs de pixel ou plus l'une de l'autre à des emplacements particuliers. Les matrices de cooccurrence de niveau de gris sont des exemples de caractéristiques de second ordre de texture statique. La matrice décrit le nombre d’occurrences d’une paire (I, J) où I est le niveau de gris d’un pixel et J est le niveau de gris d’un pixel distants ou décalés de l’autre pixel (situé à 0°, 45°, 90° ou 135° du premier). Le nombre d’occurrences sera situé à la case (I, J) de la matrice GLCM.
\\~\\
De nombreuses caractéristiques de texture peuvent être identifiées à partir de la matrice GLCM. En voici quelques-unes:
\begin{itemize}
    \item \textbf{Contraste}: Évalue la variation locale du niveau de gris dans les valeurs d'intensité des pixels
    \item \textbf{Énergie}: Le nombre de paires répétées est calculé. L'énergie doit être élevée si les paires de pixels répétées sont élevées.
    \item \textbf{Entropie}: Décrit le degré de hasard nécessaire à la compression d'image.
    \item \textbf{Homogénéité}: Teste si les paires de pixels sont homogènes. L'homogénéité est supposée être élevée si les valeurs des pixels de chaque paire de pixels sont identiques.
    \item \textbf{Corrélation}: Fournit une connexion dans la paire de pixels entre les deux pixels. La corrélation est supposée être vitale si les niveaux de gris des paires de pixels sont fortement corrélés.
\end{itemize}
\cite{ref_02}
\\~\\
Pour ce projet, j'ai utilisé la méthode « GLCM » de « scikit-image » pour créer la matrice GLCM à partir de l'image de l'iris.
\\~\\
Voici un exemple de résultat de la matrice GLCM de l'iris d'un oeil:

\begin{center}
    \includegraphics[width = 12cm]{glcm}
\end{center}

\subsection{Réduction de la dimensionnalité}
La réduction de la dimensionnalité est un processus qui consiste à réduire considérablement le nombre de caractéristiques pour faciliter le processus d’entraînement. La PCA est une technique qui permet de réduire la dimensionnalité.

\subsubsection{PCA}
L'analyse en composantes principales (PCA) est de loin l'algorithme de réduction de dimensionnalité le plus populaire. Cet algorithme identifie d'abord l'hyperplan le plus proche des données, puis projette les données sur celui-ci. Avant de pouvoir projeter les données sur l’hyperplan de dimension inférieure, on doit choisir le bon hyperplan. On doit donc choisir le bon axe avant de faire la projection des données. Dépendamment de l’axe choisi sur l’hyperplan, on peut conserver le plus possible la variance ou seulement la conserver faiblement. En conservant le plus la variance, on perdra le moins d’informations possible. L’objectif du PCA sera donc de conserver le plus de variance pour garder le plus d’informations possible. Le PCA identifiera l’axe qui représente la plus grande quantité de variance dans l'ensemble d'apprentissage. Ensuite, il trouvera l’axe qui représente la plus grande quantité de variance restante et ainsi de suite. Il trouvera autant d’axes que le nombre de dimensions de l’ensemble de données. Donc, pour deux dimensions, il identifiera 2 axes.
\cite{ref_03}
\\~\\
Pour ce projet, j'ai transformé chaque matrice 2D GLCM de chaque iris en un vecteur 1D grâce à la méthode « flatten » de « numpy ». Par la suite, j'ai ajouté tous les vecteurs 1D à un tableau.  Ensuite, j'ai appliqué la méthode « PCA » de « scikit-learn » sur le tableau de vecteurs.

\subsection{Processus de classification}
Le processus de classification est la dernière étape du système de reconnaissance. Il consiste à trouver le degré de similarité entre une image test et une image dans la base de données. Il permet de détecter si la personne est dans la base de données ou si c’est un imposteur.\cite{ref_01}\cite{ref_06}
\\~\\
Il existe de nombreuses techniques pour classifier les données. Une de ces méthodes est les k voisins les plus proches (k-NN). Elle consiste à trouver les k échantillons dont l'entrée est la plus proche d'une nouvelle entrée.

\section{Méthodologie d’évaluation}
La technique utilisée pour l'évaluation est la validation croisée. La validation croisée consiste à séparer les données en, par exemple, 10 parties stratifiés, afin d’éviter les biais. Ensuite, on entraîne et évalue les données 10 fois en choisissant 9 des sous-groupes pour l'entraînement et le dernier pour l'évaluation.\cite{ref_03}
\ \\~\\
La base de données de référence « MMU iris dataset » et un K = 10 pour la validation croisée ont été utilisés pour l'évaluation.

\section{Résultats préliminaires}
		\begin{center}
			\captionof{table}{\selectfont Matrice de confusion pour \textbf{GLCM}-\textbf{PCA} et $k$-\textbf{NN}. }
			\vspace{0.3em}
			{ \fontsize{12}{12}\selectfont  	
				\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c}
				Sujets & \textbf{005} & \textbf{010} & \textbf{013} & \textbf{022} & \textbf{027} & \textbf{030} & \textbf{032} & 						\textbf{035} & \textbf{038} & \textbf{040} \\ \hline
				\textbf{005} & \textbf{6} & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 3 \\ \hline
				\textbf{010} & 0 & \textbf{9} & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline
				\textbf{013} & 0 & 0 & \textbf{8} & 0 & 0 & 1 & 0 & 0 & 0 & 1 \\ \hline
				\textbf{022} & 0 & 1 & 0 & \textbf{8} & 1 & 0 & 0 & 0 & 0 & 0 \\ \hline
				\textbf{027} & 0 & 1 & 0 & 2 & \textbf{6} & 0 & 1 & 0 & 0 & 0 \\ \hline
				\textbf{030} & 2 & 0 & 1 & 0 & 0 & \textbf{4} & 1 & 0 & 0 & 2 \\ \hline
				\textbf{032} & 0 & 1 & 0 & 0 & 1 & 0 & \textbf{7} & 0 & 0 & 1 \\ \hline
				\textbf{035} & 0 & 1 & 0 & 0 & 1 & 1 & 0 & \textbf{7} & 0 & 0 \\ \hline
				\textbf{038} & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & \textbf{9} & 0 \\ \hline
				\textbf{040} & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & \textbf{7} \\ \hline
				\end{tabular}
			}
		\end{center}
		
	 \begin{center}
		\captionof{table}{\selectfont Comparaison des deux méthodes.}
		\vspace{0.3em}
		{ \fontsize{12}{12}\selectfont 
    	\begin{tabular}{l|c}
        	Méthode 	& Taux de reconnaissance \\ \hline
            \textbf{GLCM}-\textbf{PCA} et $k$-\textbf{NN}   & $\mathbf{71\%}$ \\ \hline
            \textbf{GLCM} et $k$-\textbf{NN}     			& $22\%$ \\ \hline
    	\end{tabular}     		
    	}
    \end{center}


\section{Conclusion}
Pour conclure, on a obtenu des résultats intéressants avec la représentation GLCM-PCA qui est bien meilleure que la simple GLCM avec caractéristiques. Malgré les bons résultats, on pourrait améliorer le processus de pré-traitement pour mieux détecter l’iris dans l’image et pour retirer le bruit comme les cils. Ceci nous permettrait d'obtenir un meilleur taux de reconnaissance.

\newpage
\bibliography{project_report_v1.0}


\end{document}